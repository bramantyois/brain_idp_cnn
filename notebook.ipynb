{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 11:26:28.412993: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from sfcn import SFCN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from volumedatagenerator import VolumeDataGeneratorRegression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_list = pd.read_csv('fields/subcortical_volumes.csv')['field id'].to_list()\n",
    "\n",
    "# columns=['path']\n",
    "# for col in col_list:\n",
    "#     columns.append(str(col)+'-2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('csv/split_train.csv', index_col='eid').dropna()\n",
    "valid_df = pd.read_csv('csv/split_valid.csv', index_col='eid').dropna()\n",
    "test_df = pd.read_csv('csv/split_test.csv', index_col='eid').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'sfcn_vanilla'\n",
    "batch_size = 5\n",
    "gpu_num = 5\n",
    "cpu_workers = 5\n",
    "epochs_num = 64\n",
    "\n",
    "index=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [182, 218, 182]\n",
    "num_output = len(train_df.columns)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = VolumeDataGeneratorRegression(\n",
    "    sample_df=train_df, \n",
    "    batch_size=batch_size, \n",
    "    #num_reg_classes=num_output, \n",
    "    dim=input_dim,\n",
    "    output_preprocessing='quantile')\n",
    "\n",
    "scaler_instance = train_gen.get_scaler_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = VolumeDataGeneratorRegression(\n",
    "    sample_df=valid_df, \n",
    "    batch_size=batch_size, \n",
    "    #num_reg_classes=num_output, \n",
    "    dim=input_dim,\n",
    "    output_scaler=scaler_instance,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = VolumeDataGeneratorRegression(\n",
    "    sample_df=test_df, \n",
    "    batch_size=batch_size, \n",
    "    #num_reg_classes=num_output, \n",
    "    dim=input_dim,\n",
    "    output_scaler=scaler_instance,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 11:26:45.214637: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-16 11:26:45.216460: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-16 11:26:45.616670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-16 11:26:45.619744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:06:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-16 11:26:45.622748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:07:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-16 11:26:45.625811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:08:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-16 11:26:45.628821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties: \n",
      "pciBusID: 0000:0c:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-16 11:26:45.631820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 5 with properties: \n",
      "pciBusID: 0000:0d:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-16 11:26:45.634635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 6 with properties: \n",
      "pciBusID: 0000:0e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-16 11:26:45.637469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 7 with properties: \n",
      "pciBusID: 0000:0f:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-16 11:26:45.637493: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-16 11:26:45.641460: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-16 11:26:45.641505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-16 11:26:45.644244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-16 11:26:45.645132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-16 11:26:45.648070: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-16 11:26:45.649756: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-16 11:26:45.672092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-16 11:26:45.720666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\n",
      "2021-12-16 11:26:45.722044: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-16 11:26:48.658885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-16 11:26:48.660102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:06:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-16 11:26:48.661286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:07:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-16 11:26:48.664594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:08:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-16 11:26:48.665797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties: \n",
      "pciBusID: 0000:0c:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-16 11:26:48.666977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 5 with properties: \n",
      "pciBusID: 0000:0d:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-16 11:26:48.668239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 6 with properties: \n",
      "pciBusID: 0000:0e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-16 11:26:48.669467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 7 with properties: \n",
      "pciBusID: 0000:0f:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-16 11:26:48.669504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-16 11:26:48.669542: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-16 11:26:48.669562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-16 11:26:48.669580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-16 11:26:48.669598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-16 11:26:48.669616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-16 11:26:48.669634: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-16 11:26:48.669653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-16 11:26:48.691755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\n",
      "2021-12-16 11:26:48.691805: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-16 11:26:52.222513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-16 11:26:52.222555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 4 5 6 7 \n",
      "2021-12-16 11:26:52.222564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y Y Y Y Y Y Y \n",
      "2021-12-16 11:26:52.222570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N Y Y Y Y Y Y \n",
      "2021-12-16 11:26:52.222576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   Y Y N Y Y Y Y Y \n",
      "2021-12-16 11:26:52.222582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   Y Y Y N Y Y Y Y \n",
      "2021-12-16 11:26:52.222587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 4:   Y Y Y Y N Y Y Y \n",
      "2021-12-16 11:26:52.222593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 5:   Y Y Y Y Y N Y Y \n",
      "2021-12-16 11:26:52.222599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 6:   Y Y Y Y Y Y N Y \n",
      "2021-12-16 11:26:52.222604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 7:   Y Y Y Y Y Y Y N \n",
      "2021-12-16 11:26:52.238611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10269 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
      "2021-12-16 11:26:52.242074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10269 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:06:00.0, compute capability: 6.1)\n",
      "2021-12-16 11:26:52.245227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10269 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:07:00.0, compute capability: 6.1)\n",
      "2021-12-16 11:26:52.248620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10269 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)\n",
      "2021-12-16 11:26:52.251966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 10269 MB memory) -> physical GPU (device: 4, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0c:00.0, compute capability: 6.1)\n",
      "2021-12-16 11:26:52.255383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 10269 MB memory) -> physical GPU (device: 5, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0d:00.0, compute capability: 6.1)\n",
      "2021-12-16 11:26:52.258625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 10269 MB memory) -> physical GPU (device: 6, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0e:00.0, compute capability: 6.1)\n",
      "2021-12-16 11:26:52.261884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 10269 MB memory) -> physical GPU (device: 7, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0f:00.0, compute capability: 6.1)\n",
      "2021-12-16 11:26:52.262564: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 182, 218, 182, 1) 0         \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv3D)              (None, 182, 218, 182, 32) 896       \n",
      "_________________________________________________________________\n",
      "batchnorm_0 (BatchNormalizat (None, 182, 218, 182, 32) 128       \n",
      "_________________________________________________________________\n",
      "maxpool_0 (MaxPooling3D)     (None, 91, 109, 91, 32)   0         \n",
      "_________________________________________________________________\n",
      "activation_0 (Activation)    (None, 91, 109, 91, 32)   0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv3D)              (None, 91, 109, 91, 64)   55360     \n",
      "_________________________________________________________________\n",
      "batchnorm_1 (BatchNormalizat (None, 91, 109, 91, 64)   256       \n",
      "_________________________________________________________________\n",
      "maxpool_1 (MaxPooling3D)     (None, 45, 54, 45, 64)    0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 45, 54, 45, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv3D)              (None, 45, 54, 45, 128)   221312    \n",
      "_________________________________________________________________\n",
      "batchnorm_2 (BatchNormalizat (None, 45, 54, 45, 128)   512       \n",
      "_________________________________________________________________\n",
      "maxpool_2 (MaxPooling3D)     (None, 22, 27, 22, 128)   0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 22, 27, 22, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv3D)              (None, 22, 27, 22, 256)   884992    \n",
      "_________________________________________________________________\n",
      "batchnorm_3 (BatchNormalizat (None, 22, 27, 22, 256)   1024      \n",
      "_________________________________________________________________\n",
      "maxpool_3 (MaxPooling3D)     (None, 11, 13, 11, 256)   0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 11, 13, 11, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv3D)              (None, 11, 13, 11, 256)   1769728   \n",
      "_________________________________________________________________\n",
      "batchnorm_4 (BatchNormalizat (None, 11, 13, 11, 256)   1024      \n",
      "_________________________________________________________________\n",
      "maxpool_4 (MaxPooling3D)     (None, 5, 6, 5, 256)      0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5, 6, 5, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv3D)              (None, 5, 6, 5, 64)       16448     \n",
      "_________________________________________________________________\n",
      "batchnorm_5 (BatchNormalizat (None, 5, 6, 5, 64)       256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5, 6, 5, 64)       0         \n",
      "_________________________________________________________________\n",
      "avgpool_15 (AveragePooling3D (None, 1, 1, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv_7 (Conv3D)              (None, 1, 1, 1, 1425)     92625     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1425)              0         \n",
      "=================================================================\n",
      "Total params: 3,044,561\n",
      "Trainable params: 3,042,961\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SFCN(\n",
    "        input_dim=[182, 218, 182, 1], \n",
    "        output_dim=num_output,\n",
    "        conv_num_filters=[32, 64, 128, 256, 256, 64], \n",
    "        conv_kernel_sizes=[3, 3, 3, 3, 3, 1], \n",
    "        conv_strides=[1, 1, 1, 1, 1, 1],\n",
    "        conv_padding=['same', 'same', 'same', 'same', 'same', 'valid'],\n",
    "        pooling_size=[2, 2, 2, 2, 2],\n",
    "        pooling_type=['max_pool', 'max_pool', 'max_pool', 'max_pool', 'max_pool'],\n",
    "        batch_norm=True,\n",
    "        dropout=False,\n",
    "        softmax=False,\n",
    "        gpu_num=gpu_num,\n",
    "        name=name+'_'+str(index)\n",
    "        )\n",
    "model.compile(learning_rate=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 11:26:55.608796: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_1696\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2021-12-16 11:26:55.628670: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-16 11:26:55.647148: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2099975000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "INFO:tensorflow:batch_all_reduce: 26 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 26 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 11:27:11.589118: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-16 11:27:13.063012: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2021-12-16 11:27:13.344215: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2021-12-16 11:27:16.052339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1238/1238 [==============================] - ETA: 0s - loss: 0.1050 - mae: 0.2709"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 11:39:03.271626: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_20050\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1238/1238 [==============================] - 929s 657ms/step - loss: 0.1050 - mae: 0.2709 - val_loss: 0.1951 - val_mae: 0.3573\n",
      "Epoch 2/64\n",
      "1238/1238 [==============================] - 814s 656ms/step - loss: 0.0827 - mae: 0.2485 - val_loss: 0.0971 - val_mae: 0.2617\n",
      "Epoch 3/64\n",
      "1238/1238 [==============================] - 805s 649ms/step - loss: 0.0798 - mae: 0.2435 - val_loss: 0.0998 - val_mae: 0.2638\n",
      "Epoch 4/64\n",
      "1238/1238 [==============================] - 805s 649ms/step - loss: 0.0754 - mae: 0.2358 - val_loss: 0.1025 - val_mae: 0.2677\n",
      "Epoch 5/64\n",
      "1238/1238 [==============================] - 815s 657ms/step - loss: 0.0714 - mae: 0.2280 - val_loss: 0.1129 - val_mae: 0.2716\n",
      "Epoch 6/64\n",
      "1238/1238 [==============================] - 797s 642ms/step - loss: 0.0682 - mae: 0.2212 - val_loss: 0.0955 - val_mae: 0.2610\n",
      "Epoch 7/64\n",
      "1238/1238 [==============================] - 796s 642ms/step - loss: 0.0666 - mae: 0.2179 - val_loss: 0.0875 - val_mae: 0.2512\n",
      "Epoch 8/64\n",
      "1238/1238 [==============================] - 806s 649ms/step - loss: 0.0650 - mae: 0.2147 - val_loss: 0.0994 - val_mae: 0.2622\n",
      "Epoch 9/64\n",
      "1238/1238 [==============================] - 808s 651ms/step - loss: 0.0637 - mae: 0.2122 - val_loss: 0.0825 - val_mae: 0.2438\n",
      "Epoch 10/64\n",
      "1238/1238 [==============================] - 806s 650ms/step - loss: 0.0624 - mae: 0.2094 - val_loss: 0.0799 - val_mae: 0.2398\n",
      "Epoch 11/64\n",
      "1238/1238 [==============================] - 803s 647ms/step - loss: 0.0615 - mae: 0.2076 - val_loss: 0.0818 - val_mae: 0.2434\n",
      "Epoch 12/64\n",
      "1238/1238 [==============================] - 802s 647ms/step - loss: 0.0606 - mae: 0.2056 - val_loss: 0.0892 - val_mae: 0.2540\n",
      "Epoch 13/64\n",
      "1238/1238 [==============================] - 805s 649ms/step - loss: 0.0598 - mae: 0.2041 - val_loss: 0.1115 - val_mae: 0.2754\n",
      "Epoch 14/64\n",
      "1238/1238 [==============================] - 815s 656ms/step - loss: 0.0590 - mae: 0.2025 - val_loss: 0.0947 - val_mae: 0.2558\n",
      "Epoch 15/64\n",
      "1238/1238 [==============================] - 821s 662ms/step - loss: 0.0577 - mae: 0.1996 - val_loss: 0.0862 - val_mae: 0.2465\n",
      "Epoch 16/64\n",
      "1238/1238 [==============================] - 816s 658ms/step - loss: 0.0568 - mae: 0.1979 - val_loss: 0.0855 - val_mae: 0.2469\n",
      "Epoch 17/64\n",
      "1238/1238 [==============================] - 820s 661ms/step - loss: 0.0557 - mae: 0.1953 - val_loss: 0.0859 - val_mae: 0.2469\n",
      "Epoch 18/64\n",
      "1238/1238 [==============================] - 812s 654ms/step - loss: 0.0546 - mae: 0.1931 - val_loss: 0.0936 - val_mae: 0.2552\n",
      "Epoch 19/64\n",
      "1238/1238 [==============================] - 806s 649ms/step - loss: 0.0536 - mae: 0.1909 - val_loss: 0.0821 - val_mae: 0.2443\n",
      "Epoch 20/64\n",
      "1238/1238 [==============================] - 812s 654ms/step - loss: 0.0525 - mae: 0.1886 - val_loss: 0.1150 - val_mae: 0.2719\n",
      "Epoch 21/64\n",
      "1238/1238 [==============================] - 808s 651ms/step - loss: 0.0519 - mae: 0.1871 - val_loss: 0.0903 - val_mae: 0.2504\n",
      "Epoch 22/64\n",
      "1238/1238 [==============================] - 817s 658ms/step - loss: 0.0513 - mae: 0.1858 - val_loss: 0.0986 - val_mae: 0.2608\n",
      "Epoch 23/64\n",
      "1238/1238 [==============================] - 807s 650ms/step - loss: 0.0503 - mae: 0.1835 - val_loss: 0.0845 - val_mae: 0.2462\n",
      "Epoch 24/64\n",
      "1238/1238 [==============================] - 806s 650ms/step - loss: 0.0499 - mae: 0.1827 - val_loss: 0.0917 - val_mae: 0.2523\n",
      "Epoch 25/64\n",
      "1238/1238 [==============================] - 812s 654ms/step - loss: 0.0494 - mae: 0.1815 - val_loss: 0.0865 - val_mae: 0.2479\n",
      "Epoch 26/64\n",
      "1238/1238 [==============================] - 812s 654ms/step - loss: 0.0487 - mae: 0.1801 - val_loss: 0.0921 - val_mae: 0.2540\n"
     ]
    }
   ],
   "source": [
    "model.train_generator(train_gen, valid_gen, batch_size=batch_size, epochs=epochs_num, workers=cpu_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 17:41:17.477232: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_129355\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2021-12-16 17:44:39.859480: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_131346\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('weights/checkpoint_' + name + '_' + str(index))\n",
    "model.evaluate_generator(valid_gen, batch_size, filename=name + '_val', workers=cpu_workers)\n",
    "model.evaluate_generator(test_gen, batch_size, filename=name + '_test', workers=cpu_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVG pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = 'sfcn_avg_pool'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SFCN(\n",
    "#         input_dim=[182, 218, 182, 1], \n",
    "#         output_dim=num_output,\n",
    "#         conv_num_filters=[32, 64, 128, 256, 256, 64], \n",
    "#         conv_kernel_sizes=[3, 3, 3, 3, 3, 1], \n",
    "#         conv_strides=[1, 1, 1, 1, 1, 1],\n",
    "#         conv_padding=['same', 'same', 'same', 'same', 'same', 'valid'],\n",
    "#         pooling_size=[2, 2, 2, 2, 2],\n",
    "#         pooling_type=['avg_pool', 'avg_pool', 'avg_pool', 'avg_pool', 'avg_pool'],\n",
    "#         batch_norm=True,\n",
    "#         dropout=False,\n",
    "#         softmax=False,\n",
    "#         gpu_num=gpu_num,\n",
    "#         name=name+'_'+str(0)\n",
    "#         )\n",
    "# model.compile(learning_rate=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train_generator(train_gen, valid_gen, batch_size=batch_size, epochs=40, workers=cpu_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('weights/checkpoint_' + name + '_' + str(0))\n",
    "# model.evaluate_generator(valid_gen, batch_size, filename=name + '_val', workers=cpu_workers)\n",
    "# model.evaluate_generator(test_gen, batch_size, filename=name + '_test', workers=cpu_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train_generator(train_gen, valid_gen, batch_size=batch_size, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('weights/checkpoint_' + name)\n",
    "#model.evaluate_generator(valid_gen, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# from datetime import date\n",
    "\n",
    "# r2 = -0.29363421770141684\n",
    "# mae = 0.27212154832328556\n",
    "# mse = 0.10790403615065694\n",
    "# today = date.today()\n",
    "\n",
    "# columns = ['date','r2','mae','mse']\n",
    "\n",
    "# # df = pd.DataFrame(entry, columns=columns, index='date')\n",
    "\n",
    "# filedir = Path.cwd().joinpath('results')\n",
    "# filedir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# fn = filedir.joinpath(name +'.csv')\n",
    "\n",
    "\n",
    "# if fn.exists():\n",
    "#     entry ={\n",
    "#         'date':today,\n",
    "#         'r2':r2,\n",
    "#         'mae':mae,\n",
    "#         'mse':mse }\n",
    "#     df = pd.read_csv(fn)    \n",
    "#     df = df.append(entry, ignore_index=True)\n",
    "# else:\n",
    "#     df = pd.DataFrame([[today, r2, mae, mse]], columns=columns)\n",
    "\n",
    "# df.to_csv(fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.model.evaluate(valid_gen)\n",
    "# train_df['path'].iloc[0]aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data_size=200\n",
    "#X = np.random.normal(loc=5, scale=5, size=(data_size, *(input_dim), 1))\n",
    "#y = np.random.normal(loc=1, scale=1, size=(data_size, num_output))\n",
    "#model.train(X, y, batch_size, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test = np.random.normal(loc=8, scale=3, size=(1, 160, 192, 160, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test = np.mean(x_test, axis=(1,2,3,4))\n",
    "#print(y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07a6a1ab2a95e05132d9ffaeb8e54a95a2d3cb5cb59827ad97cccdbb2506f6b0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
