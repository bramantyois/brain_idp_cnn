{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 12:10:03.857960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from sfcn import SFCN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from volumedatagenerator import VolumeDataGeneratorRegression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_list = pd.read_csv('fields/subcortical_volumes.csv')['field id'].to_list()\n",
    "\n",
    "# columns=['path']\n",
    "# for col in col_list:\n",
    "#     columns.append(str(col)+'-2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('csv/split_train.csv', index_col='eid').dropna()\n",
    "valid_df = pd.read_csv('csv/split_valid.csv', index_col='eid').dropna()\n",
    "test_df = pd.read_csv('csv/split_test.csv', index_col='eid').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'sfcn_avg_norm'\n",
    "batch_size = 6\n",
    "gpu_num = 6\n",
    "cpu_workers = 6\n",
    "epochs_num = 64\n",
    "\n",
    "index=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [182, 218, 182]\n",
    "num_output = len(train_df.columns)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = VolumeDataGeneratorRegression(\n",
    "    sample_df=train_df, \n",
    "    batch_size=batch_size, \n",
    "    #num_reg_classes=num_output, \n",
    "    dim=input_dim,\n",
    "    output_preprocessing='quantile')\n",
    "\n",
    "scaler_instance = train_gen.get_scaler_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gen = VolumeDataGeneratorRegression(\n",
    "    sample_df=valid_df, \n",
    "    batch_size=batch_size, \n",
    "    #num_reg_classes=num_output, \n",
    "    dim=input_dim,\n",
    "    output_scaler=scaler_instance,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = VolumeDataGeneratorRegression(\n",
    "    sample_df=test_df, \n",
    "    batch_size=batch_size, \n",
    "    #num_reg_classes=num_output, \n",
    "    dim=input_dim,\n",
    "    output_scaler=scaler_instance,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 12:10:17.309791: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-19 12:10:17.312413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-19 12:10:17.660131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-19 12:10:17.663059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:06:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-19 12:10:17.665899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:07:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-19 12:10:17.668732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:08:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-19 12:10:17.671590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties: \n",
      "pciBusID: 0000:0c:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-19 12:10:17.674403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 5 with properties: \n",
      "pciBusID: 0000:0d:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-19 12:10:17.677272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 6 with properties: \n",
      "pciBusID: 0000:0e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-19 12:10:17.680093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 7 with properties: \n",
      "pciBusID: 0000:0f:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-19 12:10:17.680113: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-19 12:10:17.684044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-19 12:10:17.684090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-19 12:10:17.686378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-19 12:10:17.687243: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-19 12:10:17.690054: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-19 12:10:17.691625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-19 12:10:17.696786: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-19 12:10:17.742027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\n",
      "2021-12-19 12:10:17.743550: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-19 12:10:20.361916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-19 12:10:20.363490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:06:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-19 12:10:20.364995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:07:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-19 12:10:20.366512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:08:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-19 12:10:20.368016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties: \n",
      "pciBusID: 0000:0c:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-19 12:10:20.369519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 5 with properties: \n",
      "pciBusID: 0000:0d:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-19 12:10:20.371039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 6 with properties: \n",
      "pciBusID: 0000:0e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-19 12:10:20.372533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 7 with properties: \n",
      "pciBusID: 0000:0f:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-12-19 12:10:20.372579: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-19 12:10:20.372628: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-19 12:10:20.372658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-12-19 12:10:20.372686: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-19 12:10:20.372713: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-19 12:10:20.372742: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-19 12:10:20.372769: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-19 12:10:20.372799: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-19 12:10:20.394774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\n",
      "2021-12-19 12:10:20.394818: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-19 12:10:23.520786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-19 12:10:23.520836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 2 3 4 5 6 7 \n",
      "2021-12-19 12:10:23.520845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y Y Y Y Y Y Y \n",
      "2021-12-19 12:10:23.520849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N Y Y Y Y Y Y \n",
      "2021-12-19 12:10:23.520854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 2:   Y Y N Y Y Y Y Y \n",
      "2021-12-19 12:10:23.520858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 3:   Y Y Y N Y Y Y Y \n",
      "2021-12-19 12:10:23.520863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 4:   Y Y Y Y N Y Y Y \n",
      "2021-12-19 12:10:23.520867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 5:   Y Y Y Y Y N Y Y \n",
      "2021-12-19 12:10:23.520872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 6:   Y Y Y Y Y Y N Y \n",
      "2021-12-19 12:10:23.520876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 7:   Y Y Y Y Y Y Y N \n",
      "2021-12-19 12:10:23.533568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10269 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
      "2021-12-19 12:10:23.536704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10269 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:06:00.0, compute capability: 6.1)\n",
      "2021-12-19 12:10:23.539568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10269 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:07:00.0, compute capability: 6.1)\n",
      "2021-12-19 12:10:23.542440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10269 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)\n",
      "2021-12-19 12:10:23.545378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 10269 MB memory) -> physical GPU (device: 4, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0c:00.0, compute capability: 6.1)\n",
      "2021-12-19 12:10:23.548381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 10269 MB memory) -> physical GPU (device: 5, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0d:00.0, compute capability: 6.1)\n",
      "2021-12-19 12:10:23.551293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 10269 MB memory) -> physical GPU (device: 6, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0e:00.0, compute capability: 6.1)\n",
      "2021-12-19 12:10:23.554158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 10269 MB memory) -> physical GPU (device: 7, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0f:00.0, compute capability: 6.1)\n",
      "2021-12-19 12:10:23.554697: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 182, 218, 182, 1) 0         \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv3D)              (None, 182, 218, 182, 32) 896       \n",
      "_________________________________________________________________\n",
      "batchnorm_0 (BatchNormalizat (None, 182, 218, 182, 32) 128       \n",
      "_________________________________________________________________\n",
      "avgpool_0 (AveragePooling3D) (None, 91, 109, 91, 32)   0         \n",
      "_________________________________________________________________\n",
      "activation_0 (Activation)    (None, 91, 109, 91, 32)   0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv3D)              (None, 91, 109, 91, 64)   55360     \n",
      "_________________________________________________________________\n",
      "batchnorm_1 (BatchNormalizat (None, 91, 109, 91, 64)   256       \n",
      "_________________________________________________________________\n",
      "avgpool_1 (AveragePooling3D) (None, 45, 54, 45, 64)    0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 45, 54, 45, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv3D)              (None, 45, 54, 45, 128)   221312    \n",
      "_________________________________________________________________\n",
      "batchnorm_2 (BatchNormalizat (None, 45, 54, 45, 128)   512       \n",
      "_________________________________________________________________\n",
      "avgpool_2 (AveragePooling3D) (None, 22, 27, 22, 128)   0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 22, 27, 22, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv3D)              (None, 22, 27, 22, 256)   884992    \n",
      "_________________________________________________________________\n",
      "batchnorm_3 (BatchNormalizat (None, 22, 27, 22, 256)   1024      \n",
      "_________________________________________________________________\n",
      "avgpool_3 (AveragePooling3D) (None, 11, 13, 11, 256)   0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 11, 13, 11, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv3D)              (None, 11, 13, 11, 256)   1769728   \n",
      "_________________________________________________________________\n",
      "batchnorm_4 (BatchNormalizat (None, 11, 13, 11, 256)   1024      \n",
      "_________________________________________________________________\n",
      "avgpool_4 (AveragePooling3D) (None, 5, 6, 5, 256)      0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5, 6, 5, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv3D)              (None, 5, 6, 5, 64)       16448     \n",
      "_________________________________________________________________\n",
      "batchnorm_5 (BatchNormalizat (None, 5, 6, 5, 64)       256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5, 6, 5, 64)       0         \n",
      "_________________________________________________________________\n",
      "avgpool_15 (AveragePooling3D (None, 1, 1, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv_7 (Conv3D)              (None, 1, 1, 1, 1425)     92625     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1425)              0         \n",
      "=================================================================\n",
      "Total params: 3,044,561\n",
      "Trainable params: 3,042,961\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SFCN(\n",
    "        input_dim=[182, 218, 182, 1], \n",
    "        output_dim=num_output,\n",
    "        conv_num_filters=[32, 64, 128, 256, 256, 64], \n",
    "        conv_kernel_sizes=[3, 3, 3, 3, 3, 1], \n",
    "        conv_strides=[1, 1, 1, 1, 1, 1],\n",
    "        conv_padding=['same', 'same', 'same', 'same', 'same', 'valid'],\n",
    "        pooling_size=[2, 2, 2, 2, 2],\n",
    "        pooling_type=['avg_pool', 'avg_pool', 'avg_pool', 'avg_pool', 'avg_pool'],\n",
    "        batch_norm=True,\n",
    "        dropout=False,\n",
    "        softmax=False,\n",
    "        gpu_num=gpu_num,\n",
    "        name=name+'_'+str(index)\n",
    "        )\n",
    "model.compile(learning_rate=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 12:10:26.819722: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_1924\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2021-12-19 12:10:26.836916: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-19 12:10:26.855121: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2099975000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "INFO:tensorflow:batch_all_reduce: 26 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 26 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 12:10:44.207343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-19 12:10:45.645983: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2021-12-19 12:10:45.960938: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2021-12-19 12:10:48.840274: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1031/1031 [==============================] - ETA: 0s - loss: 0.1071 - mae: 0.2730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 12:23:35.511694: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_23353\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1031/1031 [==============================] - 980s 775ms/step - loss: 0.1071 - mae: 0.2729 - val_loss: 0.1958 - val_mae: 0.3623\n",
      "Epoch 2/64\n",
      "1031/1031 [==============================] - 820s 793ms/step - loss: 0.0834 - mae: 0.2496 - val_loss: 2.7413 - val_mae: 1.5146\n",
      "Epoch 3/64\n",
      "1031/1031 [==============================] - 833s 806ms/step - loss: 0.0813 - mae: 0.2460 - val_loss: 0.5720 - val_mae: 0.5185\n",
      "Epoch 4/64\n",
      "1031/1031 [==============================] - 780s 754ms/step - loss: 0.0802 - mae: 0.2439 - val_loss: 0.8174 - val_mae: 0.5828\n",
      "Epoch 5/64\n",
      "1031/1031 [==============================] - 783s 757ms/step - loss: 0.0784 - mae: 0.2408 - val_loss: 0.1790 - val_mae: 0.3004\n",
      "Epoch 6/64\n",
      "1031/1031 [==============================] - 805s 779ms/step - loss: 0.0773 - mae: 0.2388 - val_loss: 0.2564 - val_mae: 0.3520\n",
      "Epoch 7/64\n",
      "1031/1031 [==============================] - 832s 805ms/step - loss: 0.0752 - mae: 0.2350 - val_loss: 0.5199 - val_mae: 0.5013\n",
      "Epoch 8/64\n",
      "1031/1031 [==============================] - 777s 752ms/step - loss: 0.0741 - mae: 0.2328 - val_loss: 0.1280 - val_mae: 0.2793\n",
      "Epoch 9/64\n",
      "1031/1031 [==============================] - 776s 751ms/step - loss: 0.0735 - mae: 0.2315 - val_loss: 0.6726 - val_mae: 0.6386\n",
      "Epoch 10/64\n",
      "1031/1031 [==============================] - 813s 786ms/step - loss: 0.0717 - mae: 0.2284 - val_loss: 0.3528 - val_mae: 0.4247\n",
      "Epoch 11/64\n",
      "1031/1031 [==============================] - 758s 733ms/step - loss: 0.0708 - mae: 0.2263 - val_loss: 0.5175 - val_mae: 0.5622\n",
      "Epoch 12/64\n",
      "1031/1031 [==============================] - 803s 776ms/step - loss: 0.0702 - mae: 0.2249 - val_loss: 0.1254 - val_mae: 0.2879\n",
      "Epoch 13/64\n",
      "1031/1031 [==============================] - 778s 752ms/step - loss: 0.0687 - mae: 0.2221 - val_loss: 0.2377 - val_mae: 0.3742\n",
      "Epoch 14/64\n",
      "1031/1031 [==============================] - 777s 752ms/step - loss: 0.0678 - mae: 0.2202 - val_loss: 0.1841 - val_mae: 0.3254\n",
      "Epoch 15/64\n",
      "1031/1031 [==============================] - 825s 798ms/step - loss: 0.0670 - mae: 0.2186 - val_loss: 0.1402 - val_mae: 0.2986\n",
      "Epoch 16/64\n",
      "1031/1031 [==============================] - 763s 738ms/step - loss: 0.0664 - mae: 0.2175 - val_loss: 0.1394 - val_mae: 0.2984\n",
      "Epoch 17/64\n",
      "1031/1031 [==============================] - 746s 721ms/step - loss: 0.0665 - mae: 0.2175 - val_loss: 0.1366 - val_mae: 0.2915\n",
      "Epoch 18/64\n",
      "1031/1031 [==============================] - 731s 707ms/step - loss: 0.0656 - mae: 0.2158 - val_loss: 0.2205 - val_mae: 0.3576\n",
      "Epoch 19/64\n",
      "1031/1031 [==============================] - 782s 756ms/step - loss: 0.0652 - mae: 0.2150 - val_loss: 0.1501 - val_mae: 0.3054\n",
      "Epoch 20/64\n",
      "1031/1031 [==============================] - 794s 768ms/step - loss: 0.0646 - mae: 0.2136 - val_loss: 0.1127 - val_mae: 0.2707\n",
      "Epoch 21/64\n",
      "1031/1031 [==============================] - 756s 731ms/step - loss: 0.0643 - mae: 0.2130 - val_loss: 0.1498 - val_mae: 0.3030\n",
      "Epoch 22/64\n",
      "1031/1031 [==============================] - 766s 740ms/step - loss: 0.0638 - mae: 0.2119 - val_loss: 0.1741 - val_mae: 0.3229\n",
      "Epoch 23/64\n",
      "1031/1031 [==============================] - 752s 727ms/step - loss: 0.0634 - mae: 0.2112 - val_loss: 0.1556 - val_mae: 0.3126\n",
      "Epoch 24/64\n",
      "1031/1031 [==============================] - 765s 740ms/step - loss: 0.0630 - mae: 0.2104 - val_loss: 0.1469 - val_mae: 0.3077\n",
      "Epoch 25/64\n",
      "1031/1031 [==============================] - 731s 707ms/step - loss: 0.0627 - mae: 0.2098 - val_loss: 0.1293 - val_mae: 0.2820\n",
      "Epoch 26/64\n",
      "1031/1031 [==============================] - 724s 700ms/step - loss: 0.0621 - mae: 0.2085 - val_loss: 0.1365 - val_mae: 0.2866\n",
      "Epoch 27/64\n",
      "1031/1031 [==============================] - 751s 726ms/step - loss: 0.0617 - mae: 0.2075 - val_loss: 0.1298 - val_mae: 0.2862\n",
      "Epoch 28/64\n",
      "1031/1031 [==============================] - 780s 755ms/step - loss: 0.0614 - mae: 0.2072 - val_loss: 0.1480 - val_mae: 0.3066\n",
      "Epoch 29/64\n",
      "1031/1031 [==============================] - 760s 735ms/step - loss: 0.0615 - mae: 0.2071 - val_loss: 0.1160 - val_mae: 0.2703\n",
      "Epoch 30/64\n",
      "1031/1031 [==============================] - 806s 779ms/step - loss: 0.0607 - mae: 0.2056 - val_loss: 0.1162 - val_mae: 0.2758\n",
      "Epoch 31/64\n",
      "1031/1031 [==============================] - 753s 728ms/step - loss: 0.0604 - mae: 0.2051 - val_loss: 0.1469 - val_mae: 0.3046\n",
      "Epoch 32/64\n",
      "1031/1031 [==============================] - 757s 732ms/step - loss: 0.0599 - mae: 0.2040 - val_loss: 0.1308 - val_mae: 0.2863\n",
      "Epoch 33/64\n",
      "1031/1031 [==============================] - 776s 751ms/step - loss: 0.0599 - mae: 0.2040 - val_loss: 0.1487 - val_mae: 0.3012\n",
      "Epoch 34/64\n",
      "1031/1031 [==============================] - 756s 731ms/step - loss: 0.0594 - mae: 0.2031 - val_loss: 0.1501 - val_mae: 0.3111\n",
      "Epoch 35/64\n",
      "1031/1031 [==============================] - 753s 728ms/step - loss: 0.0592 - mae: 0.2026 - val_loss: 0.1344 - val_mae: 0.2925\n",
      "Epoch 36/64\n",
      "1031/1031 [==============================] - 744s 719ms/step - loss: 0.0588 - mae: 0.2016 - val_loss: 0.1300 - val_mae: 0.2836\n"
     ]
    }
   ],
   "source": [
    "model.train_generator(train_gen, valid_gen, batch_size=batch_size, epochs=epochs_num, workers=cpu_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 19:59:08.878652: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_160053\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2021-12-19 20:02:14.220337: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_162273\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('weights/checkpoint_' + name + '_' + str(index))\n",
    "model.evaluate_generator(valid_gen, batch_size, filename=name + '_val', workers=cpu_workers)\n",
    "model.evaluate_generator(test_gen, batch_size, filename=name + '_test', workers=cpu_workers)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07a6a1ab2a95e05132d9ffaeb8e54a95a2d3cb5cb59827ad97cccdbb2506f6b0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
